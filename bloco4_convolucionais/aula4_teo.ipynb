{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 4 TEORIA- Redes Convolucionais\n",
    "\n",
    "Aula 4- Aula Assíncrona\n",
    "\n",
    "---\n",
    "\n",
    "## Redes Convolucionais (CNNs)\n",
    "\n",
    "- Camadas totalmente conectadas/densas vs Convolucionais\n",
    "- Convolução para imagens\n",
    "- Padding, Stride\n",
    "- Pooling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais Convolucionais\n",
    "\n",
    "### Exemplo motivador\n",
    "\n",
    "* dígitos: classificar imagens 28x28 (784 pixels) entre 10 dígitos\n",
    "\n",
    "- se formos trabalhar com redes densas, temos alguns problemas em usar uma multi-layer perceptron para esse tratamento:\n",
    "    - valores de entrada (atributos) são considerados independetnes!\n",
    "    - Não são aproveitadas relações locais entre os dados\n",
    "    - grande número de parâmetros: memória e processamento\n",
    "        - 784 parametros por neuronio, para uma camada densa de 100 neuroios: 784*100 + 100 = 78500 parametros a serem aprendidos e mantidos na memória durante o treinamento (nesse caso específico)\n",
    "\n",
    "* Por isso, para entradas em formatos de matrizes (tensores no geral) as **Redes Convolucionais** são mais eficientes!\n",
    "    * Nova terminologia:\n",
    "        * Camada convolucional (convolutional layer)\n",
    "        * Subamostragem (pooling)\n",
    "        * Mapas de Ativação (activation/feature maps)\n",
    "        * Camada densa (dense/fully connected, tipo MLP)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolução\n",
    "\n",
    "- operador que visa realizar uma combinação linear de valores locais da entrada\n",
    "    - centrado em uma posição (x,y), gera como saída um único valor de saída\n",
    "\n",
    "* obs: na prática e nos exemplos será usada a **Correlação Cruzada** e não uma convolução na teoria, uma vez que a convolução pede um \"flip\" nos eixos do filtro, o que acaba sendo mais custoso e produz resultados semelhantes da correlação cruzada\n",
    "    * os frameworks e as técnicas atuais aplicam a correlação cruzada sob nome de convolução\n",
    "\n",
    "- <img src=\"convolucao1.jpg\" width=\"500\"> \n",
    "- <img src=\"convolucao2.jpg\" width=\"500\"> \n",
    "- 7x7 -> 5x5\n",
    "\n",
    "* E se quisermos que a entrada e saída tenha o **mesmo tamanho**? adiconamos um padding (borda) na entrada, aumentando ela em duas dimensões (1 cada lado) com uma fileira só de zeros. assim mesmo que o conteúde mude da rede, a mudança é pequena e garantimos entrada e saido de mesmo tamanho se for necessário\n",
    "    * <img src=\"padding_convoluca.jpg\" width=\"500\"> \n",
    "\n",
    "- **convolução em profundidade:** entrada com vários canais\n",
    "    - filtro k x k x p, sendo p a quantidade de canais da entrada\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada Convolucional para redes neurais\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de parâmetros\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a33b474888067a6169f866e52f630d6f3672d35114c8362b477a93e2a003ce7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
