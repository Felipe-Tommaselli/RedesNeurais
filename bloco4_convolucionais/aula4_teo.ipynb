{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 4 TEORIA- Redes Convolucionais\n",
    "\n",
    "Aula 4- Aula Assíncrona\n",
    "\n",
    "---\n",
    "\n",
    "## Redes Convolucionais (CNNs)\n",
    "\n",
    "- Camadas totalmente conectadas/densas vs Convolucionais\n",
    "- Convolução para imagens\n",
    "- Padding, Stride\n",
    "- Pooling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolução\n",
    "\n",
    "- operador que visa realizar uma combinação linear de valores locais da entrada\n",
    "    - centrado em uma posição (x,y), gera como saída um único valor de saída\n",
    "\n",
    "* obs: na prática e nos exemplos será usada a **Correlação Cruzada** e não uma convolução na teoria, uma vez que a convolução pede um \"flip\" nos eixos do filtro, o que acaba sendo mais custoso e produz resultados semelhantes da correlação cruzada\n",
    "    * os frameworks e as técnicas atuais aplicam a correlação cruzada sob nome de convolução\n",
    "\n",
    "- <img src=\"convolucao1.jpg\" width=\"500\"> \n",
    "- <img src=\"convolucao2.jpg\" width=\"500\"> \n",
    "- 7x7 -> 5x5\n",
    "\n",
    "* E se quisermos que a entrada e saída tenha o **mesmo tamanho**? adiconamos um padding (borda) na entrada, aumentando ela em duas dimensões (1 cada lado) com uma fileira só de zeros. assim mesmo que o conteúde mude da rede, a mudança é pequena e garantimos entrada e saido de mesmo tamanho se for necessário\n",
    "    * <img src=\"padding_convoluca.jpg\" width=\"500\"> \n",
    "\n",
    "- **convolução em profundidade:** entrada com vários canais\n",
    "    - filtro k * k * p, sendo p a quantidade de canais da entrada\n",
    "    - na imagem 3 canais com 3 matrizes diferentes são usados, cada qual representando um dos canais do rgb, no fim, o resultado de cada canal é somado produzindo uma única saída\n",
    "    - <img src=\"conv_canal.jpg\" width=\"400\"> \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada Convolucional para redes neurais\n",
    "\n",
    "- fltro (kernel ou neuronio convolucional) w com tamanho k * k * p\n",
    "    - cada neuronio realiza a convoluçaõ da entrada e gera um volume (tensor) de saída\n",
    "\n",
    "* centrado em um pixel específico, temos: w x + b\n",
    "    * o bias é inserido depois na convolução\n",
    "\n",
    "### Mapa de ativação\n",
    "\n",
    "* o resultado da convolução é chamad de **Mapa de ativação** e sõa obtidos após a convolução com a aplicação de uma função de ativação (ex ReLU)\n",
    "    * empilhados formam um tensor d eserá a entrada da prox camada\n",
    "    * <img src=\"feature_,map.jpg\" width=\"600\"> \n",
    "\n",
    "### Como projetar uma CNN?\n",
    "\n",
    "* deve levar em conta:\n",
    "    * **tamanho da entrada** (largura, altura e profundidade)\n",
    "    * **tamanho do filtro**\n",
    "        * profundidade igual da entrada\n",
    "        * altura e largura afetam o campo receptivo local\n",
    "    * **stride** (passo nas duas direções)\n",
    "        * 1: todos pixels filtrados pelo neuronio\n",
    "        * \\> 1: salta um numero de pixels e determinada direção (convolução)\n",
    "            * saida com tamanho resuzido\n",
    "\n",
    "- stride é o passo que vc vai dar entre os pixels que vc vai chamar de central\n",
    "    - stride (2,2): varre de 2 em 2 horizontalmente até acabar, pula duas linhas verticais e continua varrendo horizontalmente\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo Conv.layers\n",
    "\n",
    "* nós podemos interpretar cada camada da rede neural como sendo um detector de padrões em um certo campo recepitvo local\n",
    "    * exemplo dos digitos:\n",
    "    \n",
    "- na primeira camada cada neuronio ta especialista em uma certa região, montando um mapa de ativação\n",
    "    - a soma deles cobre toda a área da imagem e nesse caso, forma o digito 7\n",
    "\n",
    "* a segunda camada cnvolucional é especialista em padrões geométricos, do tipo padrões horizontais, verticais e diagonais\n",
    "    * <img src=\"conv_layers.jpg\" width=\"300\"> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de parâmetros CNNs\n",
    "\n",
    "* num de params = [(k * k * p) + 1] * d\n",
    "    * peso dos filtros: k * k * p\n",
    "    * num de filtros/neuronios: d\n",
    "        * cada um gera um mapa de ativação\n",
    "    * + 1 é o termo bias de cada filtro\n",
    "\n",
    "- exemplo: entrada 32 * 32 * 3 e 3 camadas\n",
    "    - Conv.layer 1: k = 5 e d = 8\n",
    "    - Conv.layer 2: k = 3 e d = 16\n",
    "    - Conv.layer 3: k = 1 e d = 32\n",
    "\n",
    "* num params Conv.layer 1 = [(5 * 5 * 3) + 1] * 8 = 608\n",
    "* num params Conv.layer 2 = [(3 * 3 * 8) + 1] * 16 = 1168\n",
    "* num params Conv.layer 3 = [(1 * 1 * 16) + 1] * 32 = 544\n",
    "\n",
    "- obs: por que usar um filtro 1 por 1? ela faz uma convolução só em profundidade, combinando cada cada pixel de cada imagem na mesma posição \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "* opera sobre cada mapa de ativação, reduzindo a dimensão lateral\n",
    "    * max pooling: operação de máximo local\n",
    "    * average pooling: operação de média local\n",
    "\n",
    "- exemplo:\n",
    "    - <img src=\"max_pooling.jpg\" width=\"400\"> \n",
    "\n",
    "* *obs: usar stride > 1 pode substituir o pooling*\n",
    "\n",
    "-  reduzir o tamanho d entrada permite que o filtro opere em **regiões maiores da imagem**\n",
    "    - Empilhamento de camadas convolucionais aumenta o campo receptivo local não necessitando manter a resolução de entrada\n",
    "    - no exemplo o uso de filtros fez com que o mesmo filtro em um primeiro momebto que pegava a íris da pessoa, na ultima imagem passou a pegar quase metade da cara dela\n",
    "    - <img src=\"pooling.jpg\" width=\"400\"> \n",
    "\n",
    "### Global Pooling\n",
    "\n",
    "* obtem um valor por canal, como se o tamanho de pool fosse igual as dimensões laterais\n",
    "    * pooling normal: iamgem 40x40, pooling de 2x2 -> imagem final de 20x20\n",
    "    * global pooling: imagem 40x40, pooling de 40x40 -> imagem final de 1x1\n",
    "\n",
    "- a saída será a média (ou máximo) de uma matriz com só as dimensões de cada canal\n",
    "    - exemplo: numa entrada com 40 × 40 × 100, a saída será 100 dimensões\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camadas densas e saída\n",
    "\n",
    "* aplicando o pooling já visto com as convoluções\n",
    "    * <img src=\"CNN.jpg\" width=\"600\"> \n",
    "\n",
    "- no fim, aplicamos uma **camada densa fully connected (FC)**\n",
    "    - similiar a de uma MultiLayer Perceptron\n",
    "    - pode ser vista como uma projeção dos dados em uma dimensionalidade arbitraria\n",
    "    - <img src=\"CNN_comFC.jpg\" width=\"600\">\n",
    "\n",
    "* *obs: camada densa pode ser do tipo flatten*\n",
    "\n",
    "- **Saída**: comulmente densa (ex: classificação e regressão)\n",
    "    - pode ser vista como um vetor de distribuição de probabilidaaes (tipo softmax)\n",
    "    - não é densa em redes completamente convolucionas (Fully COnvolutional Newtowrks, FCN) que serão vistas pra frente\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a33b474888067a6169f866e52f630d6f3672d35114c8362b477a93e2a003ce7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
