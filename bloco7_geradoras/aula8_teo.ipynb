{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 8 TEORIA- Modelos geradores\n",
    "\n",
    "19/10 - Aula assíncrona\n",
    "> https://www.youtube.com/watch?v=1LLDe8VheUs&ab_channel=MoacirAntonelliPonti\n",
    "\n",
    "\n",
    "* Redes Geradoras\n",
    "* Autoencoders Variacionais\n",
    "* Redes adversariais: Discriminador e Gerador\n",
    "* Redes baseadas em Difusão\n",
    "\n",
    "---\n",
    "\n",
    "## Regularização, Normalização e Transferência de Aprendizado\n",
    "\n",
    "- Modelos geradores\n",
    "- Autoencoders variacionais (VAEs)\n",
    "- Redes adversárias geradoras (GANs)\n",
    "- Modelos baseados em difusão\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos geradores\n",
    "\n",
    "* Redes geradoras são modelos que aprendem a gerar novos dados\n",
    "    * tipo aquelas que geram faces de pessoas a partir de fotos reais\n",
    "\n",
    "- rede tenta aprender a distribuição que \"gera\" os dados para amostrar novos dados a partir dela\n",
    "    - aprender como é a distribuição dos dados, no exemplo é tipo uma gaussiana, logo a maior densidade de dados é no pico dela, e a menor nas extremidades\n",
    "    - <img src=\"distribuicao_dados.png\" width=\"400\">\n",
    "\n",
    "* **tipos de métodos:**\n",
    "    * **Função de densidade explítica:** buscar a função densidade igual no exemplo acima\n",
    "        * Fully Visible Belief Networks (FVBNs)\n",
    "        * Boltzmann Machines (BM)\n",
    "        * Variational Autoencoders (VAEs) - *mais comum*\n",
    "    * **Função de densidade implícita:** aprender a gerar dados sem saber a distribuição (intui a forma que os dados são gerados)\n",
    "        * Monte Carlo\n",
    "        * Likehood-free inference via classification\n",
    "        * Generative Adversarial Networks (GANs) - *mais comum*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders variacionais (VAEs)\n",
    "\n",
    "* relembrando: autoenconders tradicionais tentam codificar atributos de forma discreta, e depois decodificar para reconstruir uma estimativa do dado original\n",
    "    * obs: eles aprendem os atributos da imgem principal, e não a imagem em si (exemplo sorriso, cor da pele...) \n",
    "    * <img src=\"autoencoder2.png\" width=\"500\">\n",
    "    * *disentaglement: separar os atributos da imagem principal* \n",
    "\n",
    "- VAEs são autoencoders que aprendem a distribuição dos dados (mesma ideia acima)\n",
    "    - <img src=\"vae.png\" width=\"500\">\n",
    "    - para cada atributo, dado pelo encoder a rede vai tentar aprender a média e desvio padrão da distribuição\n",
    "    - vai ser amostrado um dado dessa distribuição \n",
    "    - essa amostra será decodificada pelo decoder\n",
    "\n",
    "* diferenças: o autoencoder codifica a imagem e tenta reconstruir ela a partir dos proprios dados, decodificando esses dados\n",
    "    * o VAE codifica a imagem e tenta reconstruir ela a partir de uma amostra da distribuição dos dados que a rede está tentando aprender\n",
    "    * <img src=\"VAE_matematicamente.png\" width=\"300\">\n",
    "\n",
    "- depois que a rede já estiver boa, é possível assumir as distribuições aprendidas são boas e podemos jogar a parte do codificador fora\n",
    "    - assim, podemos só a partir de amostrar da distribuição, gerar novos dados\n",
    "\n",
    "* Função custo ELBO (Evidence Lower Bound)\n",
    "    * L = reconstrução + divergência Kullback-Leibler (KL)\n",
    "    * L = MSE/Binary_Cross_Entropy + KL\n",
    "\n",
    "- a divergença KL é uma medida de similaridade entre duas distribuições\n",
    "    - enquanto a reconstrução tenta olhar pros valores específicos de entrada e saída, a divergencia KL olha pras distribuições inteiras\n",
    "    - <img src=\"ELBO.png\" width=\"300\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a33b474888067a6169f866e52f630d6f3672d35114c8362b477a93e2a003ce7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
