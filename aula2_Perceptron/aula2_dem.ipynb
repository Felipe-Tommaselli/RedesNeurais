{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 2 DEMONSTRAÇÃO- Multi-Layer Perceptron\n",
    "\n",
    "Aula 2- Aula Assíncrona\n",
    "\n",
    "---\n",
    "\n",
    "## Perceptrons e Multi-layer Perceptrons\n",
    "\n",
    "- Implementando um modelo de perceptron com Pytorch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Linear\n",
    "\n",
    "* construir um modelo linear com classes orientadas a objeto\n",
    "    * modelo linear: w.X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    # construtor inicializa os parametros\n",
    "    def __init__(self, num_inputs):\n",
    "        # w inicial: amostrando de uma distribuicao normal media 0 e desvio padrao 1\n",
    "        self.w = torch.normal(0, 1, (num_inputs, 1))\n",
    "        # b inicial: valor constante 1 ou 0, as vezes com 1/total de classes\n",
    "        self.b = torch.zeros(1)\n",
    "\n",
    "    # forward: de x até a saida\n",
    "    def forward(self, X):\n",
    "        # X w + b\n",
    "        return X @ self.w + self.b # multipliação e soma matricial\n",
    "\n",
    "    # funcao custo\n",
    "    def loss(self, y, y_hat):\n",
    "        yreshape = y.reshape(y_hat.shape)\n",
    "        l = (y_hat - yreshape)**2/2\n",
    "        return l.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2659],\n",
       "         [ 0.4702]]),\n",
       " tensor([[-0.7956]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(2)\n",
    "model.w, model.forward(torch.tensor([[1,1]], dtype = torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo em Prática\n",
    "\n",
    "- testar o modelo com um problema de regressão \n",
    "    - dois datasets: x e y\n",
    "        - x tem um ruído "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3648,  1.2200],\n",
       "         [ 1.5084,  2.8066],\n",
       "         [ 3.6140,  5.1815],\n",
       "         [ 6.1235,  5.9222],\n",
       "         [ 7.9385,  9.6703],\n",
       "         [ 9.4239, 10.9706],\n",
       "         [11.2241, 13.9327],\n",
       "         [13.6394, 14.5576]]),\n",
       " tensor([0., 1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(16,  dtype = torch.float32).reshape((8,2)) + torch.normal(0,0.5, (8,2))\n",
    "y =  torch.arange(8,  dtype = torch.float32)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.1119],\n",
       "         [ -0.5897],\n",
       "         [ -2.1384],\n",
       "         [ -4.9667],\n",
       "         [ -5.5019],\n",
       "         [ -6.7707],\n",
       "         [ -7.6566],\n",
       "         [-10.4202]]),\n",
       " tensor([0., 1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.forward(x)\n",
    "y_hat, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.1212)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quão bom ta esse modelo acima?\n",
    "model.loss(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valor acima é a perda quadrática média pra ess modelo, ou seja, quanto menor essa perda melhor\n",
    "\n",
    "### Modelo com gradiente\n",
    "\n",
    "- para garantir que haja uma evolução, vamos usar o gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2():\n",
    "    # construtor inicializa os parametros\n",
    "    def __init__(self, num_inputs):\n",
    "        # w inicial: amostrando de uma distribuicao normal media 0 e desvio padrao 1\n",
    "        self.w = torch.normal(0, 1, (num_inputs, 1), requires_grad=True)\n",
    "        # b inicial: valor constante 1 ou 0, as vezes com 1/total de classes\n",
    "        self.b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "    # forward: de x até a saida\n",
    "    def forward(self, X):\n",
    "        # X w + b\n",
    "        return X @ self.w + self.b # multipliação e soma matricial\n",
    "\n",
    "    # funcao custo\n",
    "    def loss(self, y, y_hat):\n",
    "        yreshape = y.reshape(y_hat.shape)\n",
    "        l = (y_hat - yreshape)**2/2\n",
    "        return l.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0002],\n",
       "         [ 5.2100],\n",
       "         [10.3726],\n",
       "         [13.6680],\n",
       "         [20.4443],\n",
       "         [23.5735],\n",
       "         [29.2613],\n",
       "         [32.3127]], grad_fn=<AddBackward0>),\n",
       " tensor(125.1773, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Model2(2)\n",
    "\n",
    "y_hat = model2.forward(x)\n",
    "y_hat, model2.loss(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* por enquanto não vamos usar, mas com esse grad_fn ativado, já poderíamos implementar o gradient descent\n",
    "\n",
    "*obs: esse model é quasee um Perceptron, falta alguns ajustes para ser um propriamente dito (tipo uma função de ativação)*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a33b474888067a6169f866e52f630d6f3672d35114c8362b477a93e2a003ce7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
