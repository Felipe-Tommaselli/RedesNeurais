{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 3 TEORIA- Otimização para Redes Neurais\n",
    "\n",
    "Aula 3- Aula Presencial\n",
    "\n",
    "---\n",
    "\n",
    "## Perceptrons e Multi-layer Perceptrons\n",
    "\n",
    "- Funções de custo\n",
    "- Convexidade\n",
    "- Gradiente\n",
    "- Descida do Gradiente Estocástica\n",
    "- Mini-batches e taxa de aprendizado\n",
    "- Momentum e Adam\n",
    "- Decaimento da taxa de aprendizado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Básico de Treinamento de Redes Neurais\n",
    "\n",
    "* idealmente deve ser convexa (mínimo global)\n",
    "\n",
    "- funções destaques:\n",
    "    - **Mean-squared-error:** \n",
    "        - par avalores contínuos\n",
    "        - mede a divergência quadrática de cada valor obtido com a saída real\n",
    "    - **Cross-Entropy:**\n",
    "        - recomendada para probabilidades\n",
    "        - teoria da informação \n",
    "        - intuição -> o numero de bits adicionais necessários para representar o evento de referencia ao invés do predito\n",
    "\n",
    "* gradient descent -> buscar mínimo global (ou quase)\n",
    "    *  <img src=\"gradient_descent.jpg\" width=\"400\"> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foward e Backward Propagation\n",
    "\n",
    "### Foward-propagation\n",
    "\n",
    "* o que é?\n",
    "    * cálculo e armazenamento das variáveis intermediárias (incluindo saídas)\n",
    "    * entrada -> saída\n",
    "\n",
    "- como funciona?\n",
    "    - considerando uma entrada x, bias b = 0, cada camada com pesos de conexão w:\n",
    "\n",
    "- **camada oculta com k neuronios**\n",
    "    - varia´vel intermediária z = W1 * x \n",
    "        - obs: W é uma matriz\n",
    "    - vetor de atiavação da camada oculta: h = f(z)\n",
    "    - o output da camada de saída é: o = W2 * h\n",
    "    - custo> L = l(o, y) = (y - o)^2\n",
    "\n",
    "* grafo:\n",
    "    * <img src=\"fowardpropagation.jpg\" width=\"400\"> \n",
    "\n",
    "### Back-propagation\n",
    "\n",
    "- o que é?\n",
    "    - propagação que utiliza a derivada ao longo das camadas para adaptar os pesos\n",
    "    - as funções de custo e de ativação devem produzir derivada útil \n",
    "\n",
    "* detalhamento\n",
    "    * calcular o gradiente dos parâmetros da rede neural\n",
    "    *  atravessa a rede em ordem reversa, da saída para a entrada\n",
    "    * saida -> entrada\n",
    "    * utiliza a regra da cadeia\n",
    "    * armazena as derivadas parciais das variáveis intermediárias com relação aos parâmetros\n",
    "\n",
    "- como funciona?\n",
    "    - considerando uma entrada x, bias b = 0, cada camada com pesos de conexão w:\n",
    "\n",
    "- **camada oculta com k neuronios**\n",
    "    - seja os parametros da rede W1 e W2, o backprpagation calcula os gradiente do custo em relação a eles\n",
    "        - del L /del W1\n",
    "    - regra da cadeia de del L / del W1 = \n",
    "        - del L / del o\n",
    "        - del o / del f(z)\n",
    "        - del f(z) / del z\n",
    "        - del z / W1\n",
    "            - multiplica tudo: del L / del W1 = del L / del o * del o / del f(z) * del f(z) / del z * del z / W1\n",
    "\n",
    "* grafo:\n",
    "    * <img src=\"backpropagation.jpg\" width=\"400\"> \n",
    "\n",
    "- **Vanishing gradient**\n",
    "    -  se ativações geram valores muito baixos não é possível adaptar\n",
    "    -  esse é um dos motivadores do uso de ReLU ao invés de Sigmóides como função de ativação\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklists para o treinamento\n",
    "\n",
    "### Inicialização\n",
    "\n",
    "- escolhas comuns:\n",
    "    - pesos w: valor aleatório pela distribuiçaõ normal entre 0 e 1 (media 0 e desvio padrao 1)\n",
    "    - bias: 0 (as vezes com 1/total de classes)\n",
    "\n",
    "### Checklist 1\n",
    "\n",
    "* o valor da função de custo nos pesos aleatórios faz sentido?\n",
    "\n",
    "### Checklist 2\n",
    "\n",
    "* decaimento de taxa de aprendizado\n",
    "    * de forma fixa ou de acordo com métricas computadas no treinamento ou validação\n",
    "\n",
    "### Checklist 3\n",
    "\n",
    "* Utilizar qual otimziador?\n",
    "    * SGD (+ Momentum)\n",
    "    * Adam\n",
    "        * esses são mais comuns e robustos\n",
    "\n",
    "### Checklist 4\n",
    "\n",
    "* Acompanhe o custo ao longo de épocas, se possível com conjunto de validação (idealmente não deve ser o teste!)\n",
    "\n",
    "-  Inicie com experimentos com poucos exemplos\n",
    "    - explore os hiperparâmetros tentando obter \"overfitting\" para um subconjunto de exemplos, obtendo custo próximo a zero, e depois refine a busca num conjunto maior\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizadores, tamanho do batch e taxa de aprendizado\n",
    "\n",
    "### Otimizadores\n",
    "\n",
    "* técnicas para otimizar a rede neural\n",
    "    * nesse caso mais relacionadas com o batch\n",
    "    * exemplo: https://gbhat.com/machine_learning/optimize_with_momentum.html\n",
    "\n",
    "- **Batch Gradient Descent**\n",
    "    - todo o batch é utilizado para o treinamento em um único passo (a média do gradient é utilizado)\n",
    "\n",
    "\n",
    "- **Stochastic Gradient Descent (SGD)**\n",
    "    - pra cada época, uma amostra do batch é escolhida aleatoriamente (estocático) para calcular o grandient descent\n",
    "    - atualização por instãncia\n",
    "    - $O$ j = $O$ j - $a$ (y^i - y i)(x i j)\n",
    "        - $a$ é o learning rate\n",
    "    - <img src=\"SBG_merged.png\" width=\"800\">\n",
    "        - o SGD é mais \"ruidoso\" por natureza e tem dificuldade em achar minimos globsais, porém, apresenta uma solução pouco custosa computacionalmente\n",
    "\n",
    "\n",
    "* **Mini Batch Gradient Descent (MBGD)**\n",
    "    * meio termo: uma parte aleatório das amostras do dataset é usado para calcular o gradient descent\n",
    "    * O$ j = $O$ j - $a$ g(Xj, Oj)\n",
    "\n",
    "- Mudamos um pouco de escopo daqui para baixo, vamos falar de outros otimizadores:\n",
    "\n",
    "* **Momentum**\n",
    "    * custo = terreno montanhoso\n",
    "        * inicio: particula com v = 0\n",
    "        * otimização: rolar a particula considerando a aceleração\n",
    "        * consequencia: velocidade ajustada cosndierando as atualizações anteriores\n",
    "        * <img src=\"momentum.jpg\" width=\"300\">\n",
    "\n",
    "- **Adam**\n",
    "    - Utiliza momentos do gradiente: o segundo momento é usado para normalizar o primeiro, evitando outliers/pontos de inflexão\n",
    "    - Funciona melhor com taxa de aprendizado menor, quando comparado ao SGD\n",
    "    -  <img src=\"adam.jpg\" width=\"250\">\n",
    "\n",
    "### Tamanho do Batch\n",
    "\n",
    "* padrão de batch é 32 \n",
    "    * **batches maiores:** estimativas mais suaves, difícil manter na memória, exige ajustar bem a **taxa de aprendizado**\n",
    "    * **batches menores**: estimativas mais ruidosas, mas que mostraram vantagens em encontrar melhores mínimos\n",
    "\n",
    "### Taxa de aprendizado\n",
    "\n",
    "* padrão é 0.01\n",
    "    * pouco adequado para alguns otimizadores\n",
    "    * pode ser pouco adequado para batchs muito grandes ou muito pequenos\n",
    "\n",
    "-  É recomendado iniciar com um valor maior, e reduzir a taxa progressivamente (learning rate scheduling)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e284ee3255a07ad8bf76694974743c4c81cb57e7c969474d752d949b11d721e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
